{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import wfdb\n",
    "import matplotlib.patheffects as path_effects\n",
    "import seaborn as sns\n",
    "from einops.layers.torch import Reduce\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 100\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "np.random.seed(seed)  # Numpy module.\n",
    "torch.manual_seed(seed)\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_path = root_dir\n",
    "        self.alldata = np.load(self.root_path) \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.alldata)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #data = self.alldata.iloc[index].values.reshape((1, 1, 1024))\n",
    "        data = self.alldata[index].reshape((1, 1, 512))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for 8x1 filter, 512 shape\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        feature_dim = 70\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.ConstantPad2d((3, 3), 0),\n",
    "            nn.Conv2d(1, 16, (1, 8), (1, 2)),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.ConstantPad2d((3, 3), 0),            \n",
    "            nn.Conv2d(16, 32, (1, 8), (1, 2)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),       \n",
    "            nn.ConstantPad2d((3, 3), 0),            \n",
    "            nn.Conv2d(32, 48, (1, 8), (1, 2)),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU(),            \n",
    "            nn.ConstantPad2d((3, 3), 0),            \n",
    "            nn.Conv2d(48, 64, (1, 8), (1, 2)),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),                \n",
    "        )\n",
    "           \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConstantPad2d((1, 0, 4, 4), 0),            \n",
    "            nn.ConvTranspose2d(64, 48, (1, 8), (1, 2), padding=4),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU(),                 \n",
    "            nn.ConstantPad2d((1, 0, 4, 4), 0),            \n",
    "            nn.ConvTranspose2d(48, 32, (1, 8), (1, 2), padding=4),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),  \n",
    "            nn.ConstantPad2d((1, 0, 4, 4), 0),            \n",
    "            nn.ConvTranspose2d(32, 16, (1, 8), (1, 2), padding=4),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),        \n",
    "            nn.ConstantPad2d((1, 0, 4, 4), 0),            \n",
    "            nn.ConvTranspose2d(16, 1, (1, 8), (1, 2), padding=4),            \n",
    "        )\n",
    "        \n",
    "        # mu and sigma\n",
    "        self.encFC1 = nn.Linear(64*32, feature_dim)\n",
    "        self.encFC2 = nn.Linear(64*32, feature_dim)\n",
    "        \n",
    "        self.decFC1 = nn.Linear(feature_dim, 64*32)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(-1, 1, 1, 64*32)\n",
    "        mu = self.encFC1(x)\n",
    "        logvar = self.encFC2(x)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logVar):\n",
    "        std = torch.exp(logVar * 0.5)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std * eps\n",
    "    \n",
    "    def decode(self, z):\n",
    "        x = F.relu(self.decFC1(z))\n",
    "        x = x.view((-1, 64, 1, 32))\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        out = self.decode(z)\n",
    "        return out, mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "model.cuda()\n",
    "summary(model, (64, 1, 1, 512), col_names=[\"input_size\", \"output_size\", \"num_params\"],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomDataset(\"../data/train_data.npy\")\n",
    "test_data = CustomDataset(\"../data/nrs_18patient_minmax_data_onechannel_test.npy\")\n",
    "valid_data = CustomDataset(\"../data/valid_data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=1)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_loss, mu, logvar, beta):\n",
    "    KLD = (-0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()))\n",
    "    return (recon_loss + beta * KLD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = Autoencoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "optimizer = optim.Adam(net.parameters(), betas=(0.9, 0.99) ,lr=1e-4)\n",
    "criterion = nn.MSELoss(reduction='sum').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(train_loss, test_loss):\n",
    "    plt.plot(train_loss, color='red', label='Train Loss')\n",
    "    plt.plot(test_loss, color='blue', label='Test Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss')\n",
    "    plt.ylabel('Epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ls, test_ls = [], []\n",
    "reconsturction_loss, KL_loss = [], []\n",
    "patience = 10\n",
    "best_train_loss = 10000\n",
    "best_test_loss = 10000\n",
    "fea_dim = 70\n",
    "# beta = 0.00001\n",
    "beta = 0\n",
    "for i in range(epochs):\n",
    "    print('----------Epoch:{}----------'.format(i+1))\n",
    "    net.train()\n",
    "    # Keeping tracking of things for displaying the progress of the training\n",
    "    local_loss = 0\n",
    "    test_sum_loss = 0\n",
    "    if i < 100:\n",
    "        beta += 0.00001/(fea_dim / 100)\n",
    "\n",
    "\n",
    "    # Performing an epoch\n",
    "    for batch in tqdm(train_dataloader):\n",
    "\n",
    "        # Sending batch to device (GPU or CPU)\n",
    "        x = batch.to(device=device, dtype=torch.float)\n",
    "\n",
    "        # Erasing the gradients stored\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Sending batch to the Autoencoder and computing the loss\n",
    "        y, mu, logVar = net(x)\n",
    "        \n",
    "        recons_loss = criterion(y, x)\n",
    "        loss = vae_loss(recons_loss, mu, logVar, beta)\n",
    "\n",
    "        # Backpropagating gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Running the optimizer\n",
    "        optimizer.step()\n",
    "        \n",
    "        local_loss += loss.item()\n",
    "    \n",
    "    reconsturction_loss.append(recons_loss.item())\n",
    "    temp_kl = loss - recons_loss\n",
    "    KL_loss.append(temp_kl.item())\n",
    "    train_ls.append(local_loss / len(train_dataloader))\n",
    "    print(\"Epoch: \" + str(i+1) + \" | training loss: {}\".format(train_ls[i]))\n",
    "    print(\"reconstruction_loss: {}, weighted_KL_diver: {}, loss: {}\".format(recons_loss, \n",
    "                    temp_kl, loss.item()))\n",
    "\n",
    "\n",
    "    if train_ls[i] >= best_train_loss:\n",
    "        patience -= 1\n",
    "    if patience == 0:\n",
    "        print(\"early stopping\")\n",
    "        plot_curve(train_ls)\n",
    "        break\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_dataloader):\n",
    "            x = batch.to(device, dtype=torch.float)\n",
    "            generate, mu, logVar = net(x)\n",
    "#             kl_divergence = -0.5 * torch.sum(1 + logVar - mu.pow(2) - logVar.exp())\n",
    "#             test_loss = criterion(generate, x) + 0.01*kl_divergence\n",
    "            test_loss = vae_loss(criterion(generate, x), mu, logVar, beta)\n",
    "            test_sum_loss += test_loss.item()\n",
    "        test_ls.append(test_sum_loss / len(valid_dataloader))\n",
    "        print(\"Epoch: \" + str(i+1) + \" | test loss: {}\".format(test_ls[i]))\n",
    "                       \n",
    "        # save best model\n",
    "        if test_ls[i] < best_test_loss:\n",
    "            best_test_loss = test_ls[i]\n",
    "            patience = 10\n",
    "            torch.save(net.state_dict(), \"VAE.pt\")\n",
    "\n",
    "plot_curve(train_ls, test_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRD(y_true, y_pred):\n",
    "    y_true, y_pred = y_true.detach().cpu().numpy()[0].reshape(512, 1), y_pred.detach().cpu().numpy()[0].reshape(512, 1)\n",
    "    return np.sqrt( np.square(y_true-y_pred).sum() / (np.square(y_true).sum()) ) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fea_dim = 70\n",
    "beta = 0.001/(fea_dim / 100)\n",
    "device = torch.device('cpu')\n",
    "net = Autoencoder()\n",
    "loaded = torch.load('../model/VAE_fea70_epoch200.pt', map_location=device)\n",
    "net.load_state_dict(loaded)\n",
    "net.eval()\n",
    "testing_loss = []\n",
    "PRD_list = []\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "    if i < 20:\n",
    "        img1 = batch.numpy().reshape(512, 1)\n",
    "        wfdb.plot_items(signal=img1, fs=128, title='Test waveform')\n",
    "    batch = batch.to(device=device, dtype=torch.float)\n",
    "    output, mu, logVar = net(batch)\n",
    "\n",
    "    temp = vae_loss(criterion(output, batch), mu, logVar, beta).item()\n",
    "    testing_loss.append(temp)\n",
    "    PRD_list.append(PRD(batch, output))\n",
    "\n",
    "    if i < 20:\n",
    "        out = output.detach().cpu().numpy()[0].reshape(512, 1)\n",
    "        wfdb.plot_items(signal=out, fs=128, title='Generate waveform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "mean_loss = np.mean(testing_loss)\n",
    "max_loss = np.max(testing_loss)\n",
    "percent_75 = np.percentile(testing_loss, 75)\n",
    "ax = sns.boxplot(x=testing_loss).set(title = 'box plot of test loss')\n",
    "print(\"mean loss: {}, max_loss: {}, 75% percentile: {}\".format(mean_loss, max_loss, percent_75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_median_labels(ax, fmt='.1f'):\n",
    "    lines = ax.get_lines()\n",
    "    boxes = [c for c in ax.get_children() if type(c).__name__ == 'PathPatch']\n",
    "    lines_per_box = int(len(lines) / len(boxes))\n",
    "    for median in lines[4:len(lines):lines_per_box]:\n",
    "        x, y = (data.mean() for data in median.get_data())\n",
    "        # choose value depending on horizontal or vertical plot orientation\n",
    "        value = x if (median.get_xdata()[1] - median.get_xdata()[0]) == 0 else y\n",
    "        text = ax.text(x, y, f'{value:{fmt}}', ha='center', va='center',\n",
    "                       fontweight='bold', color='white')\n",
    "        # create median-colored border around white text for contrast\n",
    "        text.set_path_effects([\n",
    "            path_effects.Stroke(linewidth=3, foreground=median.get_color()),\n",
    "            path_effects.Normal(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 3]\n",
    "single_PRD_box = sns.boxplot(x=PRD_list, linewidth=2.5)\n",
    "single_PRD_box.set(title = 'Box Plot of PRD (Single Channel VAE)')\n",
    "single_PRD_box.set(xlabel='PRD (%)')\n",
    "add_median_labels(single_PRD_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(PRD_list), np.percentile(PRD_list, 25), np.percentile(PRD_list, 75), np.max(PRD_list), np.min(PRD_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
