{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import wfdb\n",
    "import seaborn as sns\n",
    "import matplotlib.patheffects as path_effects\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 100\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "np.random.seed(seed)  # Numpy module.\n",
    "torch.manual_seed(seed)\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_path = root_dir\n",
    "        self.alldata = np.load(self.root_path) \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.alldata)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #data = self.alldata.iloc[index].values.reshape((1, 1, 1024))\n",
    "        data = self.alldata[index].reshape((2, 1, 512))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Multi-Channel Convolutional Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for 8x1 filter, 512 shape\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.ConstantPad2d((3, 3), 0),\n",
    "            nn.Conv2d(2, 40, (1, 8), (1, 2)),\n",
    "            nn.BatchNorm2d(40),\n",
    "            nn.ELU(),\n",
    "            nn.ConstantPad2d((3, 3), 0),            \n",
    "            nn.Conv2d(40, 20, (1, 8), (1, 2)),\n",
    "            nn.BatchNorm2d(20),\n",
    "            nn.ELU(),       \n",
    "            nn.ConstantPad2d((3, 3), 0),            \n",
    "            nn.Conv2d(20, 20, (1, 8), (1, 2)),\n",
    "            nn.BatchNorm2d(20),\n",
    "            nn.ELU(),            \n",
    "            nn.ConstantPad2d((3, 3), 0),            \n",
    "            nn.Conv2d(20, 40, (1, 8), (1, 2)),\n",
    "            nn.BatchNorm2d(40),\n",
    "            nn.ELU(),            \n",
    "            nn.ConstantPad2d((4, 3), 0),            \n",
    "            nn.Conv2d(40, 2, (1, 8), (1, 1)),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ELU(),        \n",
    "        )\n",
    "           \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConstantPad2d((1, 0, 4, 4), 0),        \n",
    "            nn.ConvTranspose2d(2, 2, (1, 8), (1, 1), padding=4),\n",
    "            nn.BatchNorm2d(2),\n",
    "            nn.ELU(),            \n",
    "            nn.ConstantPad2d((1, 0, 4, 4), 0),             \n",
    "            nn.ConvTranspose2d(2, 40, (1, 8), (1, 2), padding=4),\n",
    "            nn.BatchNorm2d(40),\n",
    "            nn.ELU(),        \n",
    "            nn.ConstantPad2d((1, 0, 4, 4), 0),            \n",
    "            nn.ConvTranspose2d(40, 20, (1, 8), (1, 2), padding=4),\n",
    "            nn.BatchNorm2d(20),\n",
    "            nn.ELU(),                 \n",
    "            nn.ConstantPad2d((1, 0, 4, 4), 0),            \n",
    "            nn.ConvTranspose2d(20, 20, (1, 8), (1, 2), padding=4),\n",
    "            nn.BatchNorm2d(20),\n",
    "            nn.ELU(),  \n",
    "            nn.ConstantPad2d((1, 0, 4, 4), 0),            \n",
    "            nn.ConvTranspose2d(20, 40, (1, 8), (1, 2), padding=4),\n",
    "            nn.BatchNorm2d(40),\n",
    "            nn.ELU(),        \n",
    "            nn.ConstantPad2d((4, 3), 0),             \n",
    "            nn.Conv2d(40, 2, (1, 8), 1), \n",
    "        )     \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "model.cuda()\n",
    "summary(model, (64, 2, 1, 512), col_names=[\"input_size\", \"output_size\", \"num_params\"],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomDataset(\"../data//train_data_multichannel.npy\")\n",
    "test_data = CustomDataset(\"../data/nrs_18patient_minmax_data_test.npy\")\n",
    "valid_data = CustomDataset(\"../data//valid_data_multichannel.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=1)\n",
    "valid_dataloader = DataLoader(valid_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = Autoencoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "optimizer = optim.Adam(net.parameters(), betas=(0.9, 0.99) ,lr=1e-4)\n",
    "criterion = nn.MSELoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(train_loss, test_loss):\n",
    "    plt.plot(train_loss, color='red', label='Train Loss')\n",
    "    plt.plot(test_loss, color='blue', label='Test Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Loss')\n",
    "    plt.ylabel('Epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ls, test_ls = [], []\n",
    "patience = 10\n",
    "best_train_loss = 10000\n",
    "best_test_loss = 10000\n",
    "for i in range(epochs):\n",
    "    print('----------Epoch:{}----------'.format(i+1))\n",
    "    net.train()\n",
    "    # Keeping tracking of things for displaying the progress of the training\n",
    "    local_loss = 0\n",
    "    test_sum_loss = 0\n",
    "\n",
    "    # Performing an epoch\n",
    "    for batch in tqdm(train_dataloader):\n",
    "\n",
    "        # Sending batch to device (GPU or CPU)\n",
    "        x = batch.to(device=device, dtype=torch.float)\n",
    "\n",
    "        # Erasing the gradients stored\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Sending batch to the Autoencoder and computing the loss\n",
    "        y = net(x)\n",
    "        loss = criterion(y, x)\n",
    "\n",
    "        # Backpropagating gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Running the optimizer\n",
    "        optimizer.step()\n",
    "        \n",
    "        local_loss += loss.item()\n",
    "    \n",
    "    train_ls.append(local_loss / len(train_dataloader))\n",
    "    print(\"Epoch: \" + str(i+1) + \" | training loss: {}\".format(train_ls[i]))    \n",
    "\n",
    "    if train_ls[i] >= best_train_loss:\n",
    "        patience -= 1\n",
    "    if patience == 0:\n",
    "        print(\"early stopping\")\n",
    "        plot_curve(train_ls)\n",
    "        break\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_dataloader):\n",
    "            x = batch.to(device, dtype=torch.float)\n",
    "            generate = net(x)\n",
    "            test_loss = criterion(generate, x)\n",
    "            test_sum_loss += test_loss.item()\n",
    "        test_ls.append(test_sum_loss / len(valid_dataloader))\n",
    "        print(\"Epoch: \" + str(i+1) + \" | test loss: {}\".format(test_ls[i]))\n",
    "                       \n",
    "        # save best model\n",
    "        if test_ls[i] < best_test_loss:\n",
    "            best_test_loss = test_ls[i]\n",
    "            patience = 10\n",
    "            torch.save(net.state_dict(), \"FCVE_multi_epoch200.pt\")\n",
    "\n",
    "plot_curve(train_ls, test_ls)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRD(y_true, y_pred):\n",
    "    y_true, y_pred = y_true.detach().numpy()[0].reshape((512, 2)), y_pred.detach().numpy()[0].reshape(512, 2)\n",
    "    return np.sqrt( np.square(y_true-y_pred).sum() / (np.square(y_true).sum()) ) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = Autoencoder()\n",
    "loaded = torch.load('../model/FCVE_multi_epoch200.pt', map_location=device)\n",
    "net.load_state_dict(loaded)\n",
    "net.eval()\n",
    "testing_loss = []\n",
    "PRD_list = []\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "    if i < 20:\n",
    "        img1 = batch[0].numpy().reshape((512, 2))\n",
    "        wfdb.plot_items(signal=img1, fs=128, title='Test waveform')\n",
    "    \n",
    "    output = net(batch.to(dtype=torch.float))\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    temp = criterion(output, batch).item()\n",
    "    testing_loss.append(temp)\n",
    "    PRD_list.append(PRD(batch, output))\n",
    "    \n",
    "    if i < 20:\n",
    "        out = output[0].detach().numpy().reshape((512, 2))\n",
    "        wfdb.plot_items(signal=out, fs=128, title='Generate waveform')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "mean_loss = np.mean(testing_loss)\n",
    "max_loss = np.max(testing_loss)\n",
    "percent_75 = np.percentile(testing_loss, 75)\n",
    "ax = sns.boxplot(x=testing_loss).set(title = 'box plot of test loss')\n",
    "print(\"mean loss: {}, max_loss: {}, 75% percentile: {}\".format(mean_loss, max_loss, percent_75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_median_labels(ax, fmt='.1f'):\n",
    "    lines = ax.get_lines()\n",
    "    boxes = [c for c in ax.get_children() if type(c).__name__ == 'PathPatch']\n",
    "    lines_per_box = int(len(lines) / len(boxes))\n",
    "    for median in lines[4:len(lines):lines_per_box]:\n",
    "        x, y = (data.mean() for data in median.get_data())\n",
    "        # choose value depending on horizontal or vertical plot orientation\n",
    "        value = x if (median.get_xdata()[1] - median.get_xdata()[0]) == 0 else y\n",
    "        text = ax.text(x, y, f'{value:{fmt}}', ha='center', va='center',\n",
    "                       fontweight='bold', color='white')\n",
    "        # create median-colored border around white text for contrast\n",
    "        text.set_path_effects([\n",
    "            path_effects.Stroke(linewidth=3, foreground=median.get_color()),\n",
    "            path_effects.Normal(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 3]\n",
    "single_PRD_box = sns.boxplot(x=PRD_list, linewidth=2.5)\n",
    "single_PRD_box.set(title = 'Box Plot of PRD (Multiple Channels FCAE)')\n",
    "single_PRD_box.set(xlabel='PRD (%)')\n",
    "add_median_labels(single_PRD_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(PRD_list), np.percentile(PRD_list, 25), np.percentile(PRD_list, 75), np.max(PRD_list), np.min(PRD_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
